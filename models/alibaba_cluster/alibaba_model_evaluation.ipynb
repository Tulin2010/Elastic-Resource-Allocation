{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conventional-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "isolated-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.extra.model import ModelDistribution\n",
    "from src.extra.pprint import print_model\n",
    "from src.core.core import reset_model\n",
    "\n",
    "from src.greedy.greedy import greedy_algorithm\n",
    "from src.greedy.resource_allocation_policy import SumPercentage\n",
    "from src.greedy.server_selection_policy import SumResources\n",
    "from src.greedy.task_prioritisation import UtilityDeadlinePerResource\n",
    "\n",
    "from src.optimal.fixed_optimal import fixed_optimal\n",
    "from src.core.fixed_task import FixedTask, SumSpeedPowFixedPrioritisation\n",
    "\n",
    "alibaba_model = ModelDistribution('../realistic.mdl', num_tasks=100, num_servers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecological-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result, tasks, servers):\n",
    "    print(f'Social welfare: {result.social_welfare:.3f}, Percentage tasks allocated: {result.percentage_tasks_allocated:.3f}\\n')\n",
    "    for server in servers:\n",
    "        storage_usage = sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity\n",
    "        computational_usage = sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity\n",
    "        bandwidth_usage = sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity\n",
    "        print(f'{server.name} resouce usage - Stor: {storage_usage:.3f}, Comp: {computational_usage:.3f}, Band: {bandwidth_usage:.3f}')\n",
    "    \n",
    "    avg_loading_speed = np.mean([task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_speed = np.mean([task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_speed = np.mean([task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'\\nAvg loading speed: {avg_loading_speed}, compute speed: {avg_compute_speed}, sending speed: {avg_sending_speed}')\n",
    "    avg_loading_time = np.mean([task.required_storage / task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_time = np.mean([task.required_computation / task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_time = np.mean([task.required_results_data / task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'Avg loading time: {avg_loading_time}, compute time: {avg_compute_time}, sending time: {avg_sending_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decimal-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "alibaba_model.storage_scaling = 100\n",
    "alibaba_model.computational_scaling = 0.25\n",
    "alibaba_model.results_data_scaling = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "voluntary-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, servers = alibaba_model.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "settled-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 756.980, Percentage tasks allocated: 0.970\n",
      "\n",
      "medium 0 resouce usage - Stor: 0.980, Comp: 0.010, Band: 0.180\n",
      "large 1 resouce usage - Stor: 1.000, Comp: 0.011, Band: 0.167\n",
      "xlarge 2 resouce usage - Stor: 0.990, Comp: 0.036, Band: 0.130\n",
      "large 3 resouce usage - Stor: 0.987, Comp: 0.015, Band: 0.180\n",
      "large 4 resouce usage - Stor: 1.000, Comp: 0.050, Band: 0.287\n",
      "xlarge 5 resouce usage - Stor: 0.990, Comp: 0.091, Band: 0.250\n",
      "xlarge 6 resouce usage - Stor: 0.990, Comp: 0.091, Band: 0.320\n",
      "large 7 resouce usage - Stor: 1.000, Comp: 0.027, Band: 0.173\n",
      "2xlarge 8 resouce usage - Stor: 0.976, Comp: 0.081, Band: 0.356\n",
      "large 9 resouce usage - Stor: 0.987, Comp: 0.031, Band: 0.193\n",
      "\n",
      "Avg loading speed: 1.5257731958762886, compute speed: 12.948453608247423, sending speed: 2.5670103092783507\n",
      "Avg loading time: 6.632547864506628, compute time: 21.156490446898314, sending time: 18.675733433738284\n"
     ]
    }
   ],
   "source": [
    "result = greedy_algorithm(tasks, servers, UtilityDeadlinePerResource(), SumResources(), SumPercentage())\n",
    "print_results(result, tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proof-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_model(tasks, servers)\n",
    "fixed_tasks = [FixedTask(task, SumSpeedPowFixedPrioritisation()) for task in tasks]\n",
    "foreknowledge_fixed_tasks = [FixedTask(task, SumSpeedPowFixedPrioritisation(), resource_foreknowledge=True) \n",
    "                             for task in tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developing-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 361.060, Percentage tasks allocated: 0.260\n",
      "\n",
      "medium 0 resouce usage - Stor: 0.800, Comp: 0.588, Band: 0.880\n",
      "large 1 resouce usage - Stor: 0.800, Comp: 0.350, Band: 1.000\n",
      "xlarge 2 resouce usage - Stor: 0.690, Comp: 0.942, Band: 1.000\n",
      "large 3 resouce usage - Stor: 0.867, Comp: 0.662, Band: 1.000\n",
      "large 4 resouce usage - Stor: 0.800, Comp: 0.375, Band: 0.967\n",
      "xlarge 5 resouce usage - Stor: 0.990, Comp: 0.558, Band: 0.995\n",
      "xlarge 6 resouce usage - Stor: 0.300, Comp: 0.163, Band: 0.925\n",
      "large 7 resouce usage - Stor: 0.867, Comp: 0.237, Band: 0.940\n",
      "2xlarge 8 resouce usage - Stor: 0.952, Comp: 0.184, Band: 0.984\n",
      "large 9 resouce usage - Stor: 0.667, Comp: 0.312, Band: 0.973\n",
      "\n",
      "Avg loading speed: 57.88461538461539, compute speed: 391.8269230769231, sending speed: 5.576923076923077\n",
      "Avg loading time: 0.5378205128205128, compute time: 0.03716700103984153, sending time: 8.323568205298974\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "creative-focus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 758.170, Percentage tasks allocated: 0.990\n",
      "\n",
      "medium 0 resouce usage - Stor: 1.000, Comp: 0.014, Band: 0.240\n",
      "large 1 resouce usage - Stor: 1.000, Comp: 0.029, Band: 0.387\n",
      "xlarge 2 resouce usage - Stor: 1.000, Comp: 0.015, Band: 0.285\n",
      "large 3 resouce usage - Stor: 1.000, Comp: 0.021, Band: 0.440\n",
      "large 4 resouce usage - Stor: 1.000, Comp: 0.017, Band: 0.273\n",
      "xlarge 5 resouce usage - Stor: 1.000, Comp: 0.020, Band: 0.335\n",
      "xlarge 6 resouce usage - Stor: 1.000, Comp: 0.022, Band: 0.515\n",
      "large 7 resouce usage - Stor: 1.000, Comp: 0.050, Band: 0.720\n",
      "2xlarge 8 resouce usage - Stor: 1.000, Comp: 0.027, Band: 0.504\n",
      "large 9 resouce usage - Stor: 1.000, Comp: 0.034, Band: 0.593\n",
      "\n",
      "Avg loading speed: 3.1717171717171717, compute speed: 5.9393939393939394, sending speed: 4.292929292929293\n",
      "Avg loading time: 4.4204790563302145, compute time: 27.86787455577056, sending time: 13.313455259667379\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(foreknowledge_fixed_tasks, servers, time_limit=10)\n",
    "print_results(result, foreknowledge_fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
