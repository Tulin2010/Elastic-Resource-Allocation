{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.extra.model import ModelDistribution\n",
    "from src.extra.pprint import print_model\n",
    "from src.core.core import reset_model\n",
    "\n",
    "from src.greedy.greedy import greedy_algorithm\n",
    "from src.greedy.resource_allocation_policy import SumPercentage\n",
    "from src.greedy.server_selection_policy import SumResources\n",
    "from src.greedy.task_prioritisation import UtilityDeadlinePerResource\n",
    "\n",
    "from src.optimal.fixed_optimal import fixed_optimal\n",
    "from src.core.fixed_task import FixedTask, SumSpeedPowFixedAllocationPriority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result, tasks, servers):\n",
    "    print(f'Social welfare: {result.social_welfare:.3f}, Percentage social welfare: {result.percentage_social_welfare:.3f}, Percentage tasks: {result.percentage_tasks_allocated:.3f}\\n')\n",
    "    # for server in servers:\n",
    "    #    storage_usage = sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity\n",
    "    #    computational_usage = sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity\n",
    "    #    bandwidth_usage = sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity\n",
    "    #    print(f'{server.name} resouce usage - Stor: {storage_usage:.3f}, Comp: {computational_usage:.3f}, Band: {bandwidth_usage:.3f}')\n",
    "    print(f'Server avg storage: {np.mean([sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity for server in servers]):3.2f}, '\n",
    "          f'computation: {np.mean([sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity for server in servers]):3.2f}, '\n",
    "          f'bandwidth: {np.mean([sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity for server in servers]):3.2f}')\n",
    "    \n",
    "    avg_loading_speed = np.mean([task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_speed = np.mean([task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_speed = np.mean([task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'\\nTask avg loading speed: {avg_loading_speed:3.2f}, compute speed: {avg_compute_speed:3.2f}, sending speed: {avg_sending_speed:3.2f}')\n",
    "    avg_loading_time = np.mean([task.required_storage / task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_time = np.mean([task.required_computation / task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_time = np.mean([task.required_results_data / task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'Task avg loading time: {avg_loading_time:3.2f}, compute time: {avg_compute_time:3.2f}, sending time: {avg_sending_time:3.2f}')\n",
    "    \n",
    "\n",
    "def avg_resource(tasks, attribute):\n",
    "    return np.mean([getattr(task, attribute) for task in tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alibaba_model = ModelDistribution('../alibaba.mdl', num_tasks=40, num_servers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks - required_storage: 52.00, required_computation: 1617.35, required_results_data: 17.95\n",
      "\n",
      "Fixed tasks - required_storage: 149.62, required_computation: 4061.25, required_results_data: 17.95\n",
      "Fixed tasks - loading_speed: 45.45, compute_speed: 72.50, sending_speed: 9.35\n",
      "\n",
      "Foreknowledge fixed tasks - required_storage: 52.00, required_computation: 1617.35, required_results_data: 17.95\n",
      "Foreknowledge fixed tasks - loading_speed: 12.03, compute_speed: 23.10, sending_speed: 9.35\n"
     ]
    }
   ],
   "source": [
    "tasks, servers = alibaba_model.generate()\n",
    "print('Tasks - ' + ', '.join([f\"{var}: {avg_resource(tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "\n",
    "fixed_tasks = [FixedTask(task, SumSpeedPowFixedAllocationPriority()) for task in tasks]\n",
    "print('\\nFixed tasks - ' + ', '.join([f\"{var}: {avg_resource(fixed_tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "print('Fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(fixed_tasks, var):3.2f}\" for var in [\"loading_speed\", \"compute_speed\", \"sending_speed\"]]))\n",
    "\n",
    "foreknowledge_fixed_tasks = [FixedTask(task, SumSpeedPowFixedAllocationPriority(), resource_foreknowledge=True) for task in tasks]\n",
    "print('\\nForeknowledge fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(foreknowledge_fixed_tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "print('Foreknowledge fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(foreknowledge_fixed_tasks, var):3.2f}\" for var in [\"loading_speed\", \"compute_speed\", \"sending_speed\"]]))\n",
    "\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n",
    "# for ax, var in zip(axs.flatten(), ['required_storage', 'required_computation', 'required_results_data', 'deadline']):\n",
    "#     ax.hist([getattr(task, var) for task in tasks], bins=20)\n",
    "#     ax.set_title(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 387.200, Percentage social welfare: 0.867, Percentage tasks: 0.800\n",
      "\n",
      "Server avg storage: 0.44, computation: 0.89, bandwidth: 0.87\n",
      "\n",
      "Task avg loading speed: 5.16, compute speed: 18.75, sending speed: 3.03\n",
      "Task avg loading time: 12.14, compute time: 36.27, sending time: 6.15\n"
     ]
    }
   ],
   "source": [
    "result = greedy_algorithm(tasks, servers, UtilityDeadlinePerResource(), SumResources(), SumPercentage())\n",
    "print_results(result, tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 117.650, Percentage social welfare: 0.263, Percentage tasks: 0.175\n",
      "\n",
      "Server avg storage: 0.19, computation: 0.49, bandwidth: 0.29\n",
      "\n",
      "Task avg loading speed: 10.29, compute speed: 50.00, sending speed: 3.43\n",
      "Task avg loading time: 16.16, compute time: 100.00, sending time: 7.50\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 298.420, Percentage social welfare: 0.668, Percentage tasks: 0.650\n",
      "\n",
      "Server avg storage: 0.31, computation: 0.45, bandwidth: 0.99\n",
      "\n",
      "Task avg loading speed: 6.50, compute speed: 11.23, sending speed: 5.15\n",
      "Task avg loading time: 10.17, compute time: 48.87, sending time: 4.29\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(foreknowledge_fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, foreknowledge_fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([92., 82., 74., 73., 61., 54., 50., 44., 41., 36., 40., 36., 25.,\n",
       "        23., 21., 27., 16., 25., 12., 12., 13., 14., 13.,  8., 20., 11.,\n",
       "         6., 10.,  7.,  6.,  9.,  3.,  4.,  2.,  6.,  2.,  4.,  4.,  0.,\n",
       "         1.,  4.,  2.,  1.,  0.,  1.,  2.,  0.,  1.,  0.,  2.]),\n",
       " array([ 0.17 ,  1.202,  2.234,  3.266,  4.298,  5.33 ,  6.362,  7.394,\n",
       "         8.426,  9.458, 10.49 , 11.522, 12.554, 13.586, 14.618, 15.65 ,\n",
       "        16.682, 17.714, 18.746, 19.778, 20.81 , 21.842, 22.874, 23.906,\n",
       "        24.938, 25.97 , 27.002, 28.034, 29.066, 30.098, 31.13 , 32.162,\n",
       "        33.194, 34.226, 35.258, 36.29 , 37.322, 38.354, 39.386, 40.418,\n",
       "        41.45 , 42.482, 43.514, 44.546, 45.578, 46.61 , 47.642, 48.674,\n",
       "        49.706, 50.738, 51.77 ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alibaba_model = ModelDistribution('../alibaba.mdl', num_tasks=1000, num_servers=10)\n",
    "tasks, servers = alibaba_model.generate()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist([task.value for task in tasks], bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
