{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.extra.model import ModelDistribution\n",
    "from src.extra.pprint import print_model\n",
    "from src.core.core import reset_model\n",
    "\n",
    "from src.greedy.greedy import greedy_algorithm\n",
    "from src.greedy.resource_allocation_policy import SumPercentage\n",
    "from src.greedy.server_selection_policy import SumResources\n",
    "from src.greedy.task_prioritisation import UtilityDeadlinePerResource\n",
    "\n",
    "from src.optimal.fixed_optimal import fixed_optimal\n",
    "from src.core.fixed_task import FixedTask, SumSpeedPowFixedAllocationPriority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result, tasks, servers):\n",
    "    print(f'Social welfare: {result.social_welfare:.3f}, Percentage social welfare: {result.percentage_social_welfare:.3f}, Percentage tasks: {result.percentage_tasks_allocated:.3f}\\n')\n",
    "    # for server in servers:\n",
    "    #    storage_usage = sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity\n",
    "    #    computational_usage = sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity\n",
    "    #    bandwidth_usage = sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity\n",
    "    #    print(f'{server.name} resouce usage - Stor: {storage_usage:.3f}, Comp: {computational_usage:.3f}, Band: {bandwidth_usage:.3f}')\n",
    "    print(f'Server avg storage: {np.mean([sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity for server in servers]):3.2f}, '\n",
    "          f'computation: {np.mean([sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity for server in servers]):3.2f}, '\n",
    "          f'bandwidth: {np.mean([sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity for server in servers]):3.2f}')\n",
    "    \n",
    "    avg_loading_speed = np.mean([task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_speed = np.mean([task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_speed = np.mean([task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'\\nTask avg loading speed: {avg_loading_speed:3.2f}, compute speed: {avg_compute_speed:3.2f}, sending speed: {avg_sending_speed:3.2f}')\n",
    "    avg_loading_time = np.mean([task.required_storage / task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_time = np.mean([task.required_computation / task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_time = np.mean([task.required_results_data / task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'Task avg loading time: {avg_loading_time:3.2f}, compute time: {avg_compute_time:3.2f}, sending time: {avg_sending_time:3.2f}')\n",
    "    \n",
    "\n",
    "def avg_resource(tasks, attribute):\n",
    "    return np.mean([getattr(task, attribute) for task in tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alibaba_model = ModelDistribution('../alibaba.mdl', num_tasks=40, num_servers=10)\n",
    "alibaba_model.storage_scaling = 500\n",
    "alibaba_model.computational_scaling = 1\n",
    "alibaba_model.results_data_scaling = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks - required_storage: 61.20, required_computation: 632.73, required_results_data: 22.02\n",
      "\n",
      "Fixed tasks - required_storage: 148.62, required_computation: 1877.50, required_results_data: 22.02\n",
      "Fixed tasks - loading_speed: 39.45, compute_speed: 73.75, sending_speed: 9.68\n",
      "\n",
      "Foreknowledge fixed tasks - required_storage: 61.20, required_computation: 632.73, required_results_data: 22.02\n",
      "Foreknowledge fixed tasks - loading_speed: 12.68, compute_speed: 22.95, sending_speed: 9.68\n"
     ]
    }
   ],
   "source": [
    "tasks, servers = alibaba_model.generate()\n",
    "print('Tasks - ' + ', '.join([f\"{var}: {avg_resource(tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "\n",
    "fixed_tasks = [FixedTask(task, SumSpeedPowFixedAllocationPriority()) for task in tasks]\n",
    "print('\\nFixed tasks - ' + ', '.join([f\"{var}: {avg_resource(fixed_tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "print('Fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(fixed_tasks, var):3.2f}\" for var in [\"loading_speed\", \"compute_speed\", \"sending_speed\"]]))\n",
    "\n",
    "foreknowledge_fixed_tasks = [FixedTask(task, SumSpeedPowFixedAllocationPriority(), resource_foreknowledge=True) for task in tasks]\n",
    "print('\\nForeknowledge fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(foreknowledge_fixed_tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "print('Foreknowledge fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(foreknowledge_fixed_tasks, var):3.2f}\" for var in [\"loading_speed\", \"compute_speed\", \"sending_speed\"]]))\n",
    "\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n",
    "# for ax, var in zip(axs.flatten(), ['required_storage', 'required_computation', 'required_results_data', 'deadline']):\n",
    "#     ax.hist([getattr(task, var) for task in tasks], bins=20)\n",
    "#     ax.set_title(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 414.720, Percentage social welfare: 0.933, Percentage tasks: 0.850\n",
      "\n",
      "Server avg storage: 0.51, computation: 0.72, bandwidth: 0.90\n",
      "\n",
      "Task avg loading speed: 6.03, compute speed: 19.62, sending speed: 3.68\n",
      "Task avg loading time: 15.96, compute time: 22.06, sending time: 6.48\n"
     ]
    }
   ],
   "source": [
    "result = greedy_algorithm(tasks, servers, UtilityDeadlinePerResource(), SumResources(), SumPercentage())\n",
    "print_results(result, tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 220.460, Percentage social welfare: 0.496, Percentage tasks: 0.275\n",
      "\n",
      "Server avg storage: 0.39, computation: 0.82, bandwidth: 0.62\n",
      "\n",
      "Task avg loading speed: 16.73, compute speed: 68.18, sending speed: 5.45\n",
      "Task avg loading time: 12.92, compute time: 38.36, sending time: 5.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixed optimal different objective values - cplex: 220.46 and running task values: 220.45999999999998\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 382.280, Percentage social welfare: 0.860, Percentage tasks: 0.600\n",
      "\n",
      "Server avg storage: 0.35, computation: 0.34, bandwidth: 0.99\n",
      "\n",
      "Task avg loading speed: 8.92, compute speed: 13.12, sending speed: 6.62\n",
      "Task avg loading time: 9.92, compute time: 31.27, sending time: 4.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixed optimal different objective values - cplex: 382.28 and running task values: 382.28000000000003\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(foreknowledge_fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, foreknowledge_fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
