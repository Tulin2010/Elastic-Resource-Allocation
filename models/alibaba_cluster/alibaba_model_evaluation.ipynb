{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.extra.model import ModelDistribution\n",
    "from src.extra.pprint import print_model\n",
    "from src.core.core import reset_model\n",
    "\n",
    "from src.greedy.greedy import greedy_algorithm\n",
    "from src.greedy.resource_allocation_policy import SumPercentage\n",
    "from src.greedy.server_selection_policy import SumResources\n",
    "from src.greedy.task_prioritisation import UtilityDeadlinePerResource\n",
    "\n",
    "from src.optimal.fixed_optimal import fixed_optimal\n",
    "from src.core.fixed_task import FixedTask, SumSpeedPowFixedAllocationPriority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result, tasks, servers):\n",
    "    print(f'Social welfare: {result.social_welfare:.3f}, Percentage social welfare: {result.percentage_social_welfare:.3f}, Percentage tasks: {result.percentage_tasks_allocated:.3f}\\n')\n",
    "    # for server in servers:\n",
    "    #    storage_usage = sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity\n",
    "    #    computational_usage = sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity\n",
    "    #    bandwidth_usage = sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity\n",
    "    #    print(f'{server.name} resouce usage - Stor: {storage_usage:.3f}, Comp: {computational_usage:.3f}, Band: {bandwidth_usage:.3f}')\n",
    "    print(f'Server avg storage: {np.mean([sum(task.required_storage for task in server.allocated_tasks) / server.storage_capacity for server in servers]):3.2f}, '\n",
    "          f'computation: {np.mean([sum(task.compute_speed for task in server.allocated_tasks) / server.computation_capacity for server in servers]):3.2f}, '\n",
    "          f'bandwidth: {np.mean([sum(task.loading_speed + task.sending_speed for task in server.allocated_tasks) / server.bandwidth_capacity for server in servers]):3.2f}')\n",
    "    \n",
    "    avg_loading_speed = np.mean([task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_speed = np.mean([task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_speed = np.mean([task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'\\nTask avg loading speed: {avg_loading_speed:3.2f}, compute speed: {avg_compute_speed:3.2f}, sending speed: {avg_sending_speed:3.2f}')\n",
    "    avg_loading_time = np.mean([task.required_storage / task.loading_speed for task in tasks if task.running_server])\n",
    "    avg_compute_time = np.mean([task.required_computation / task.compute_speed for task in tasks if task.running_server])\n",
    "    avg_sending_time = np.mean([task.required_results_data / task.sending_speed for task in tasks if task.running_server])\n",
    "    print(f'Task avg loading time: {avg_loading_time:3.2f}, compute time: {avg_compute_time:3.2f}, sending time: {avg_sending_time:3.2f}')\n",
    "    \n",
    "\n",
    "def avg_resource(tasks, attribute):\n",
    "    return np.mean([getattr(task, attribute) for task in tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alibaba_model = ModelDistribution('../alibaba.mdl', num_tasks=40, num_servers=10)\n",
    "alibaba_model.storage_scaling = 500\n",
    "alibaba_model.computational_scaling = 1\n",
    "alibaba_model.results_data_scaling = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks - required_storage: 42.85, required_computation: 541.83, required_results_data: 15.88\n",
      "\n",
      "Fixed tasks - required_storage: 156.50, required_computation: 1792.50, required_results_data: 15.88\n",
      "Fixed tasks - loading_speed: 56.25, compute_speed: 75.00, sending_speed: 9.95\n",
      "\n",
      "Foreknowledge fixed tasks - required_storage: 42.85, required_computation: 541.83, required_results_data: 15.88\n",
      "Foreknowledge fixed tasks - loading_speed: 13.00, compute_speed: 24.20, sending_speed: 9.95\n"
     ]
    }
   ],
   "source": [
    "tasks, servers = alibaba_model.generate()\n",
    "print('Tasks - ' + ', '.join([f\"{var}: {avg_resource(tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "\n",
    "fixed_tasks = [FixedTask(task, SumSpeedPowFixedAllocationPriority()) for task in tasks]\n",
    "print('\\nFixed tasks - ' + ', '.join([f\"{var}: {avg_resource(fixed_tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "print('Fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(fixed_tasks, var):3.2f}\" for var in [\"loading_speed\", \"compute_speed\", \"sending_speed\"]]))\n",
    "\n",
    "foreknowledge_fixed_tasks = [FixedTask(task, SumSpeedPowFixedAllocationPriority(), resource_foreknowledge=True) for task in tasks]\n",
    "print('\\nForeknowledge fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(foreknowledge_fixed_tasks, var):3.2f}\" for var in [\"required_storage\", \"required_computation\", \"required_results_data\"]]))\n",
    "print('Foreknowledge fixed tasks - ' + ', '.join([f\"{var}: {avg_resource(foreknowledge_fixed_tasks, var):3.2f}\" for var in [\"loading_speed\", \"compute_speed\", \"sending_speed\"]]))\n",
    "\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n",
    "# for ax, var in zip(axs.flatten(), ['required_storage', 'required_computation', 'required_results_data', 'deadline']):\n",
    "#     ax.hist([getattr(task, var) for task in tasks], bins=20)\n",
    "#     ax.set_title(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 392.570, Percentage social welfare: 0.945, Percentage tasks: 0.925\n",
      "\n",
      "Server avg storage: 0.44, computation: 0.88, bandwidth: 0.95\n",
      "\n",
      "Task avg loading speed: 5.97, compute speed: 26.46, sending speed: 3.73\n",
      "Task avg loading time: 10.65, compute time: 20.51, sending time: 5.94\n"
     ]
    }
   ],
   "source": [
    "result = greedy_algorithm(tasks, servers, UtilityDeadlinePerResource(), SumResources(), SumPercentage())\n",
    "print_results(result, tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 213.370, Percentage social welfare: 0.503, Percentage tasks: 0.400\n",
      "\n",
      "Server avg storage: 0.59, computation: 0.81, bandwidth: 0.84\n",
      "\n",
      "Task avg loading speed: 15.31, compute speed: 62.50, sending speed: 4.12\n",
      "Task avg loading time: 10.13, compute time: 60.00, sending time: 5.08\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social welfare: 333.410, Percentage social welfare: 0.787, Percentage tasks: 0.800\n",
      "\n",
      "Server avg storage: 0.36, computation: 0.31, bandwidth: 0.99\n",
      "\n",
      "Task avg loading speed: 6.44, compute speed: 10.59, sending speed: 5.03\n",
      "Task avg loading time: 8.06, compute time: 41.52, sending time: 3.86\n"
     ]
    }
   ],
   "source": [
    "reset_model(tasks, servers)\n",
    "result = fixed_optimal(foreknowledge_fixed_tasks, servers, time_limit=4)\n",
    "print_results(result, foreknowledge_fixed_tasks, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
