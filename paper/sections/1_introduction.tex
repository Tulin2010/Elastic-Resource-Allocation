\section{Introduction}
\label{sec:introduction}
In the last few years, cloud computing has become a popular solution for running data-intensive applications remotely~\cite{cloud_cite}. However, large-scale data centres are often not feasible for application domains that require low latency or fast application performance~\cite{mobile_edge_IoT}. To deal with such domains, \emph{edge computing} (and similar approaches in fog computing) have emerged as a complementary paradigm, allowing tasks to be executed at the edge of networks, close to the user, in small data centers known as \emph{edge nodes}.

With the growth of the Internet of Things (IoT), edge computing has become a key enabling technology~\cite{mobile_edge_IoT, edge_computing_iot}, in particular for applications in smart cities~\cite{mobile_edge_smart}, disaster response scenarios~\cite{mobile_edge_disaster, smart_disaster_management} and home automation systems~\cite{home_automations}. In these applications, low-power devices generate data or tasks that cannot be computed on  chip, so edge nodes are used to process such tasks. More specifically, an example in disaster relief~\cite{9200963} is the use of drones to map an area, allowing emergency services to locate survivors. Using edge nodes, drone video can be analysed and combined together locally to provide essential information for organising a response. 

A key challenge in these settings is that edge nodes typically have limited resources~\cite{7796149} and may be shared between many competing tasks. Thus, this paper focuses on the allocation of tasks to edge nodes to maximise social welfare (i.e., the sum of completed task values). This is particularly challenging, since task owners are typically self-interested, causing them to behave strategically~\cite{Bi2019}. Furthermore, they may prefer not to reveal their task values to a central allocation mechanism~\cite{Pai2013}.

An important shortcoming of existing work~\cite{ghobaei2019resource, 8373684, tasiopoulos2018edge, 8839780, 8379445} on resource allocation is that it assumes tasks have strict resource requirements --- that is, each task must be allocated a fixed amount of CPU cycles or bandwidth by a server. This is often achieved by giving users a limited selection of virtual machine (VM) specifications that can be used for their task. However, this can cause an inefficient allocation of resources and bottlenecks on certain server resources, as it provides no flexibility to the server for how its resources are distributed.

However, such strict resource allocation is not necessarily required due to the inherent elasticity that tasks have in how they can utilise resources. An example of such elasticity is the time taken for the data of a task to be transmitted to an edge node (or to send back results), this is generally proportional to the bandwidth allocated. Similarly, more CPU cycles could be allocated to a task, in order to ensure that it completes more quickly. Together, this allows edge nodes to balance bandwidth and CPU resources flexibly to ensure that tasks complete within their respective deadlines. This notion of elasticity is different from other work~\cite{ServerElasticity} that uses elasticity to refer to the ability of cloud servers to respond to system resource usage by expanding server capacity when needed. To highlight this difference, we refer to \emph{resource-elastic tasks} in this paper.

Within related work, there exists a wide range of approaches to resource management~\cite{ghobaei2019resource}, some of which use auction mechanisms to deal with competition~\cite{KUMAR2017234,Zhang2017,Du2019,Bi2019}. Other work has focused on increasing system flexibility by allowing users to have extremely short deadlines (10\:ms - 50\:ms)~\cite{tasiopoulos2018edge}, the ability for servers to offload tasks to other servers~\cite{8373684} and to be able to efficiently distribute data centers, such that users are geographically closer to edge nodes~\cite{8839780}. This paper expands such flexibility to the server's resource allocation mechanism, enabling novel elasticity of resources allocated to tasks.
%% Todo add more related work

Our problem (outlined in Subsection~\ref{subsec:optimisation-problem}) is related to multidimensional knapsack problems, for which there is a large body of research~\cite{knapsacks, numbers}. However, little work has been done to allow for flexibility of item weights with constraints that must be fulfilled for the item to be allocated, as in our problem. Nip \textit{et al.}~\cite{Nip2017} have formulated a pseudo-polynomial time complexity algorithm for a similar problem. However, their work differs from ours due to using non-linear constraints instead of linear constraints.

%% This is originally by Fidan but modified by mark
Against this background, we make the following novel contributions to the state of the art:
\begin{itemize}
    \item We formulate an optimisation problem allowing elastic resource allocation by servers, whose objective is to maximise total social welfare, taking into account resource limitations and task deadlines.
    \item We prove that this problem is NP-hard and propose an approximation algorithm with polynomial computational complexity, $O(\left|J\right| \left|I\right| + n^3)$.
    \item We propose two auction-based mechanisms to deal with the self-interested nature of users, one based on previous research and the other being a novel mechanism. These offer various trade-offs regarding truthfulness, optimality, scalability, information requirements from users and decentralisation.
    \item Using extensive simulations, we compare the performance of our algorithms against prior work, and show that our algorithms outperform them by around 20\%, while at the same time being within 95\% of the optimal solution.
\end{itemize}

In the following section (Section~\ref{sec:problem-formulation}), we present our system model, formal optimisation problem and an example case to show the effectiveness of elastic resource allocation. Using the developed formulation, Section~\ref{sec:flexible-resource-allocation-mechanisms} presents our three algorithms. Section~\ref{sec:empirical-results} presents an extensive analysis of our algorithms and finally, Section~\ref{sec:conclusion-and-future-work} summarises our key findings before suggesting future work. 